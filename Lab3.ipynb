{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDK4xckzmqA/n6WngNyD3k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaGon/kpi/blob/intelligent-data-analysis/Lab3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "A6zZheU3OHYP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random, os, math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Повнозв'язані нейронні мережі"
      ],
      "metadata": {
        "id": "Hgt8NxypSHvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = kagglehub.dataset_download(\"atharvasoundankar/global-cybersecurity-threats-2015-2024\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "df = pd.read_csv(os.path.join(path, \"Global_Cybersecurity_Threats_2015-2024.csv\"))\n",
        "\n",
        "print(\"Назви колонок:\")\n",
        "for col in df.columns:\n",
        "    print(col)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Size rows/columns:\", df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39OaJrwmSgao",
        "outputId": "ce86deae-d129-40cd-c1c5-c2b257f3ea81"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/atharvasoundankar/global-cybersecurity-threats-2015-2024?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47.0k/47.0k [00:00<00:00, 1.63MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Path to dataset files: /root/.cache/kagglehub/datasets/atharvasoundankar/global-cybersecurity-threats-2015-2024/versions/1\n",
            "Назви колонок:\n",
            "Country\n",
            "Year\n",
            "Attack Type\n",
            "Target Industry\n",
            "Financial Loss (in Million $)\n",
            "Number of Affected Users\n",
            "Attack Source\n",
            "Security Vulnerability Type\n",
            "Defense Mechanism Used\n",
            "Incident Resolution Time (in Hours)\n",
            "\n",
            "\n",
            "Size rows/columns: (3000, 10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qb546rV_YuVc",
        "outputId": "17e8c228-bc52-405d-8e81-c1b89d0605fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Попередня обробка**"
      ],
      "metadata": {
        "id": "FiWGlUu2xNIZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SIZE  = 0.2\n",
        "VAL_SIZE   = 0.2 # розмір валідації,\n",
        "RANDOM_SEED = 42\n",
        "BATCH_SIZE = 128\n",
        "LR = 1e-3 # швидкість навчання\n",
        "EPOCHS = 50\n",
        "PATIENCE = 3\n",
        "TGT = \"Incident Resolution Time (in Hours)\"\n",
        "DROP_COLS = [\"Year\"]\n",
        "\n",
        "\n",
        "# Фіксация випадкових чисел для відтворюваності\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "\n",
        "y = pd.qcut(df[TGT], q=3, labels=[\"short\",\"medium\",\"long\"])\n",
        "print(\"Overall class counts:\\n\", y.value_counts())\n",
        "\n",
        "\n",
        "X = df.drop(columns=DROP_COLS + [TGT])\n",
        "\n",
        "\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED, stratify=y\n",
        ")\n",
        "\n",
        "num_cols = X_train_raw.select_dtypes(include=[\"number\"]).columns.tolist()\n",
        "cat_cols = [c for c in X_train_raw.columns if c not in num_cols]\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "try:\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "except TypeError:\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "cat_pipe = Pipeline([\n",
        "    (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "    (\"ohe\", ohe)\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    [(\"num\", num_pipe, num_cols),\n",
        "     (\"cat\", cat_pipe, cat_cols)]\n",
        ")\n",
        "\n",
        "print(\"\\n================================\")\n",
        "print(\"Train class distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"\\n================================\")\n",
        "print(\"Test  class distribution:\\n\", y_test.value_counts(normalize=True))\n",
        "\n",
        "\n",
        "X_train_np = preprocessor.fit_transform(X_train_raw)\n",
        "X_test_np  = preprocessor.transform(X_test_raw)\n",
        "\n",
        "X_tr_np, X_val_np, y_tr, y_val = train_test_split(\n",
        "    X_train_np, y_train, test_size=VAL_SIZE,\n",
        "    random_state=RANDOM_SEED, stratify=y_train\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUg_e5Rmw8BV",
        "outputId": "5cc4d63b-5cc2-43f3-877e-147e4b9f955b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall class counts:\n",
            " Incident Resolution Time (in Hours)\n",
            "short     1026\n",
            "medium     991\n",
            "long       983\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================\n",
            "Train class distribution:\n",
            " Incident Resolution Time (in Hours)\n",
            "short     0.342083\n",
            "medium    0.330417\n",
            "long      0.327500\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "================================\n",
            "Test  class distribution:\n",
            " Incident Resolution Time (in Hours)\n",
            "short     0.341667\n",
            "medium    0.330000\n",
            "long      0.328333\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split label**"
      ],
      "metadata": {
        "id": "PJqoGOGkxesq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# short/medium/long до 0/1/2\n",
        "classes = [\"short\",\"medium\",\"long\"]\n",
        "cls2id = {c:i for i,c in enumerate(classes)}\n",
        "y_tr_id   = np.array([cls2id[v] for v in y_tr], dtype=np.int64)\n",
        "y_val_id  = np.array([cls2id[v] for v in y_val], dtype=np.int64)\n",
        "y_test_id = np.array([cls2id[v] for v in y_test], dtype=np.int64)\n",
        "\n",
        "input_dim = X_tr_np.shape[1]; n_classes = len(classes)\n",
        "print(f\"Input dimentions: {input_dim} | Classes: {classes}\")\n"
      ],
      "metadata": {
        "id": "Kh-KqJ-qxGBA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6091737c-417a-4919-bb9c-c42daf5814e0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dimentions: 38 | Classes: ['short', 'medium', 'long']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TORCH DATASETS/LOADERS**"
      ],
      "metadata": {
        "id": "GFqEXgqzxJsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TabularDS(Dataset):\n",
        "    def __init__(self, X_np, y_np):\n",
        "        self.X = torch.tensor(X_np, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y_np, dtype=torch.long) # X_np та y_np перетворюються у тензори PyTorch.\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_loader = DataLoader(TabularDS(X_tr_np,  y_tr_id),  batch_size=BATCH_SIZE, shuffle=True) # Створює батчі для тренування, перемішує дані.\n",
        "val_loader   = DataLoader(TabularDS(X_val_np, y_val_id), batch_size=256, shuffle=False)\n",
        "test_loader  = DataLoader(TabularDS(X_test_np,y_test_id),batch_size=256, shuffle=False)\n",
        "\n",
        "\n",
        "class MLP(nn.Module): # багатошаровий (2) перцептрон\n",
        "    def __init__(self, in_dim, out_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 256), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128),   nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(128, out_dim)\n",
        "        )\n",
        "    def forward(self, x): return self.net(x)\n",
        "\n",
        "model = MLP(input_dim, n_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()  # qcut gives balanced classes, so no weights needed\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "best_val = float(\"inf\"); epochs_no_improve = 0\n",
        "best_path = \"best_mlp_incident_time.pth\"\n",
        "train_loss_hist, val_loss_hist = [], []\n",
        "\n",
        "# TRAIN with early stopping\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    tr_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device) #Вмикається режим тренування, проходимо батчі\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(xb), yb)\n",
        "        loss.backward(); optimizer.step()\n",
        "        tr_loss += loss.item()\n",
        "    tr_loss /= max(1, len(train_loader))\n",
        "\n",
        "    model.eval(); va_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in val_loader: # Режим оцінювання, без градієнтів\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            va_loss += criterion(model(xb), yb).item()\n",
        "    va_loss /= max(1, len(val_loader))\n",
        "\n",
        "    train_loss_hist.append(tr_loss); val_loss_hist.append(va_loss)\n",
        "    print(f\"[{epoch:02d}] train_loss={tr_loss:.4f} | val_loss={va_loss:.4f}\")\n",
        "\n",
        "    if va_loss < best_val: # Виводимо втрати\n",
        "        best_val = va_loss; epochs_no_improve = 0\n",
        "        torch.save(model.state_dict(), best_path)\n",
        "        print(\"  → saved best\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= PATIENCE:\n",
        "            print(\"Early stopping\"); break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGMMLqfJbJva",
        "outputId": "a66316c4-b60e-4f30-83da-616f48fea42c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[01] train_loss=1.1005 | val_loss=1.1003\n",
            "  → saved best\n",
            "[02] train_loss=1.0926 | val_loss=1.1007\n",
            "[03] train_loss=1.0881 | val_loss=1.1028\n",
            "[04] train_loss=1.0828 | val_loss=1.1068\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load best and evaluate**"
      ],
      "metadata": {
        "id": "D7Cxcw3kxTdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_model = MLP(input_dim, n_classes).to(device)\n",
        "best_model.load_state_dict(torch.load(best_path, map_location=device))\n",
        "best_model.eval()\n",
        "print(\"Best model loaded.\")\n",
        "\n",
        "def eval_model(model, loader):\n",
        "    all_y, all_p = [], []\n",
        "    with torch.no_grad():\n",
        "        for xb, yb in loader:\n",
        "            pred = model(xb.to(device)).argmax(1).cpu().numpy()\n",
        "            all_p.append(pred); all_y.append(yb.numpy())\n",
        "    y_true = np.concatenate(all_y); y_pred = np.concatenate(all_p)\n",
        "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 4))\n",
        "    print(\"Macro-F1:\", round(f1_score(y_true, y_pred, average=\"macro\"), 4))\n",
        "    print(\"\\nClassification report:\\n\",\n",
        "          classification_report(y_true, y_pred, target_names=classes))\n",
        "    print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "    return y_true, y_pred\n",
        "\n",
        "print(\"\\n=== MLP (Incident time: short/medium/long) — TEST ===\")\n",
        "y_true, y_pred = eval_model(best_model, test_loader)\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(range(1, len(train_loss_hist)+1), train_loss_hist, \"o-\", label=\"Train loss\")\n",
        "plt.plot(range(1, len(val_loss_hist)+1),   val_loss_hist,   \"-\",  label=\"Val loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\"); plt.title(\"MLP: Training vs Validation Loss\")\n",
        "plt.legend(); plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "zm7TkkonxtjU",
        "outputId": "52817129-164e-4a2b-c8fe-f1c91dcbb1f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best model loaded.\n",
            "\n",
            "=== MLP (Incident time: short/medium/long) — TEST ===\n",
            "Accuracy: 0.33\n",
            "Macro-F1: 0.3273\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       short       0.32      0.36      0.34       205\n",
            "      medium       0.35      0.38      0.37       198\n",
            "        long       0.32      0.25      0.28       197\n",
            "\n",
            "    accuracy                           0.33       600\n",
            "   macro avg       0.33      0.33      0.33       600\n",
            "weighted avg       0.33      0.33      0.33       600\n",
            "\n",
            "Confusion matrix:\n",
            " [[73 79 53]\n",
            " [69 76 53]\n",
            " [86 62 49]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для задачі класифікації часу розв’язання інцидентів за даними «Global Cybersecurity Threats (2015–2024)» було побудовано повнозв’язану нейронну мережу (MLP) прямого поширення. Модель навчалася на збалансованих класах («short», «medium», «long»), з попередньою обробкою числових і категоріальних ознак (імпутація, стандартизація, one-hot encoding).\n",
        "Отримана точність (≈ 33 %) є співставною з класичними алгоритмами — логістичною регресією, випадковим лісом і SVM.\n",
        "\n",
        "Втрата train падає\n",
        "\n",
        "Втрата test зростає\n",
        "\n",
        "Рання зупинка після 4 епох, через перенавчання.\n",
        "\n",
        "Модель швидко підбирає прості шаблони в навчальному наборі, але не може узагальнювати далі, що свідчить про обмежений сигнал або необхідність більшої мережі та тривалішого навчання."
      ],
      "metadata": {
        "id": "YGjJ9hv-hN25"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Згорткові нейронні мережі"
      ],
      "metadata": {
        "id": "Q3ghTm4gjt6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import kagglehub\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "yEvx9j60xxO_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "csv_path = os.path.join(base_path, \"Training_set.csv\")\n",
        "img_dir  = os.path.join(base_path, \"train\")\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "le = LabelEncoder()\n",
        "df[\"y\"] = le.fit_transform(df[\"label\"])\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", num_classes)\n",
        "\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=SEED, stratify=df[\"y\"]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U8iopuV_XX4",
        "outputId": "826d06f5-f1fb-4471-9804-c1c794dedba9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'butterfly-image-classification' dataset.\n",
            "Device: cpu\n",
            "Classes: 75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ButterflyDS(Dataset):\n",
        "    def __init__(self, df, img_dir, tfm):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.dir = img_dir\n",
        "        self.tfm = tfm\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, i):\n",
        "        row = self.df.iloc[i]\n",
        "        img = Image.open(os.path.join(self.dir, row[\"filename\"])).convert(\"RGB\")\n",
        "        img = self.tfm(img)\n",
        "        return img, int(row[\"y\"]) #Повертаємо тензор зображення та цілочисельна мітка класу y\n",
        "\n",
        "\n",
        "# Transforms (small & large)\n",
        "\n",
        "tfm_small_train = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "tfm_small_test = transforms.Compose([\n",
        "    transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "imagenet_mean = [0.485,0.456,0.406] #Середні значення та стандартні відхилення по каналах, як у ImageNet\n",
        "imagenet_std  = [0.229,0.224,0.225]\n",
        "tfm_large_train = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "tfm_large_test = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "\n",
        "#  Dataloaders\n",
        "train_ds_small = ButterflyDS(train_df, img_dir, tfm_small_train)\n",
        "test_ds_small  = ButterflyDS(test_df,  img_dir, tfm_small_test)\n",
        "train_ds_large = ButterflyDS(train_df, img_dir, tfm_large_train)\n",
        "test_ds_large  = ButterflyDS(test_df,  img_dir, tfm_large_test)\n",
        "\n",
        "train_loader_small = DataLoader(train_ds_small, batch_size=64, shuffle=True, num_workers=0, pin_memory=False)\n",
        "test_loader_small  = DataLoader(test_ds_small,  batch_size=128, shuffle=False, num_workers=0, pin_memory=False)\n",
        "train_loader_large = DataLoader(train_ds_large, batch_size=32, shuffle=True, num_workers=0, pin_memory=False)\n",
        "test_loader_large  = DataLoader(test_ds_large,  batch_size=64, shuffle=False, num_workers=0, pin_memory=False)"
      ],
      "metadata": {
        "id": "h9rC3qap_nCb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, loader):\n",
        "    model.eval(); correct=total=0\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in loader:\n",
        "            xb,yb=xb.to(device),yb.to(device)\n",
        "            pred=model(xb).argmax(1)\n",
        "            correct+=(pred==yb).sum().item(); total+=yb.size(0)\n",
        "    return correct/total\n",
        "\n",
        "def train_model(model, train_loader, test_loader, epochs=5, lr=1e-3, freeze=None):\n",
        "    model=model.to(device)\n",
        "    if freeze:\n",
        "        for n,p in model.named_parameters():\n",
        "            if freeze in n: p.requires_grad=False\n",
        "    opt=torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "    loss_fn=nn.CrossEntropyLoss()\n",
        "    best_acc=0\n",
        "    for ep in range(1,epochs+1):\n",
        "        model.train(); total_loss=0\n",
        "        t0=time.time()\n",
        "        for xb,yb in train_loader:\n",
        "            xb,yb=xb.to(device),yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            loss=loss_fn(model(xb), yb)\n",
        "            loss.backward(); opt.step()\n",
        "            total_loss+=loss.item()\n",
        "        acc=accuracy(model,test_loader)\n",
        "        print(f\"[{ep:02d}] loss={total_loss/len(train_loader):.4f} acc={acc:.4f} time={time.time()-t0:.1f}s\")\n",
        "        if acc>best_acc: best_acc=acc\n",
        "    return best_acc, model\n",
        "\n"
      ],
      "metadata": {
        "id": "6Ygo86TsoUc1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Згорткова мережа  (convolutional neural network)**"
      ],
      "metadata": {
        "id": "EMSjeaZV1LJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2), # 64 до 32\n",
        "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),# 32  до 16\n",
        "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d(1)  # -> [B,64,1,1]\n",
        "        )\n",
        "        self.classifier=nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64,n_classes)\n",
        "        )\n",
        "    def forward(self,x): return self.classifier(self.features(x))\n",
        "\n",
        "print(\"Lightweight CNN (64x64)\")\n",
        "cnn=SmallCNN(num_classes)\n",
        "acc_cnn,cnn=train_model(cnn,train_loader_small,test_loader_small,epochs=6,lr=1e-3)\n",
        "print(f\" CNN accuracy: {acc_cnn:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcKR8jid_pgy",
        "outputId": "1569079b-c072-4cb8-a634-7ff5da721100"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lightweight CNN (64x64)\n",
            "[01] loss=4.3084 acc=0.0254 time=34.3s\n",
            "[02] loss=4.1179 acc=0.0292 time=28.3s\n",
            "[03] loss=3.9844 acc=0.0738 time=28.1s\n",
            "[04] loss=3.7903 acc=0.0931 time=30.3s\n",
            "[05] loss=3.6149 acc=0.1100 time=30.9s\n",
            "[06] loss=3.4931 acc=0.1415 time=28.3s\n",
            " CNN accuracy: 0.1415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Transfer Learning (MobileNetV3-Small)\n",
        "print(\"Transfer Learning (MobileNetV3-Small)\")\n",
        "mobilenet=models.mobilenet_v3_small(weights=models.MobileNet_V3_Small_Weights.DEFAULT)\n",
        "mobilenet.classifier[-1]=nn.Linear(mobilenet.classifier[-1].in_features,num_classes)\n",
        "\n",
        "# Freeze backbone (fast training)\n",
        "for p in mobilenet.features.parameters(): p.requires_grad=False\n",
        "acc_head,mobilenet=train_model(mobilenet,train_loader_large,test_loader_large,epochs=4,lr=1e-3)\n",
        "\n",
        "# Unfreeze all and fine-tune a bit\n",
        "for p in mobilenet.parameters(): p.requires_grad=True\n",
        "acc_ft,mobilenet=train_model(mobilenet,train_loader_large,test_loader_large,epochs=3,lr=3e-4)\n",
        "\n",
        "print(\"\\SUMMARY\")\n",
        "print(f\"Small CNN: {acc_cnn:.4f}\")\n",
        "print(f\"MobileNetV3 (head): {acc_head:.4f}\")\n",
        "print(f\"MobileNetV3 (fine-tuned): {acc_ft:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6AUfob8_rn0",
        "outputId": "6d23899a-7cbd-403f-e141-0ea75af484b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:16: SyntaxWarning: invalid escape sequence '\\S'\n",
            "<>:16: SyntaxWarning: invalid escape sequence '\\S'\n",
            "/tmp/ipython-input-4026361125.py:16: SyntaxWarning: invalid escape sequence '\\S'\n",
            "  print(\"\\SUMMARY\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transfer Learning (MobileNetV3-Small)\n",
            "[01] loss=1.7350 acc=0.7915 time=112.8s\n",
            "[02] loss=0.5872 acc=0.8408 time=105.4s\n",
            "[03] loss=0.3949 acc=0.8454 time=104.6s\n",
            "[04] loss=0.3093 acc=0.8615 time=104.5s\n",
            "[01] loss=0.1825 acc=0.8854 time=229.6s\n",
            "[02] loss=0.0898 acc=0.9023 time=230.3s\n",
            "[03] loss=0.0573 acc=0.9038 time=247.3s\n",
            "\\SUMMARY\n",
            "Small CNN: 0.1415\n",
            "MobileNetV3 (head): 0.8615\n",
            "MobileNetV3 (fine-tuned): 0.9038\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проведені експерименти дозволили порівняти ефективність двох підходів до класифікації зображень: власної легкої згорткової нейронної мережі та моделі Transfer Learning, побудованої на основі архітектури MobileNetV3-Small. Аналіз отриманих результатів продемонстрував суттєву різницю у продуктивності та здатності моделей до узагальнення.\n",
        "\n",
        "Легка згорткова нейронна мережа, тренована на зображеннях розміром 64×64, показала дуже низьку точність, що не перевищувала приблизно 14 %. Протягом усіх епох функція втрат залишалася високою, а сама модель не демонструвала ознак успішного навчання. Це свідчить про недостатню глибину та обмежений модельний потенціал такої архітектури, який не дозволяє їй виокремлювати інформативні ознаки у складних наборах даних. Отримані результати вказують на те, що подібні спрощені мережі можуть бути придатними лише для дуже простих задач, але не забезпечують адекватної точності у реальних сценаріях, де структура зображень є складнішою.\n",
        "\n",
        "Натомість модель, побудована за допомогою Transfer Learning на базі MobileNetV3-Small, продемонструвала разюче вищу ефективність. Уже на ранніх етапах навчання спостерігалося швидке зниження функції втрат та значне зростання точності, а після завершення fine-tuning модель досягла рівня точності близько 90 %. Це пояснюється тим, що вихідна архітектура MobileNetV3-Сmall містить багаторівневі, глибокі ознаки, сформовані на великому наборі даних, що забезпечує потужну початкову репрезентативність. Процес донавчання дозволив адаптувати ці ознаки до конкретної задачі, не втрачаючи їх загальної універсальності. Незважаючи на довший час обробки однієї епохи, такий підхід демонструє суттєво кращу збіжність та стабільність, що робить його значно ефективнішим у практичних застосуваннях.\n",
        "\n",
        "Узагальнюючи результати, можна стверджувати, що використання Transfer Learning на базі сучасних глибоких архітектур забезпечує значно кращі показники точності та узагальнення порівняно із тренуванням власних легких моделей з нуля. Експеримент підтверджує, що для задач класифікації зображень високої складності оптимальним рішенням є застосування вже попередньо натренованих моделей з подальшим адаптивним донавчанням, тоді як спрощені CNN-архітектури не здатні забезпечити прийнятного рівня ефективності."
      ],
      "metadata": {
        "id": "Ls361bsnxaPY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.  Вирішіть задачу класифікації текстів"
      ],
      "metadata": {
        "id": "mWOxzOsSo5ch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n",
        "import os, re, string, random, numpy as np, pandas as pd\n",
        "import torch, torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import kagglehub\n",
        "import nltk\n",
        "import gensim\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_fq8G16cAGPO",
        "outputId": "fb124a68-d1ed-4240-fe9e-7040637380de"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "print(\"Device:\", device)\n",
        "\n",
        "\n",
        "#  Load dataset\n",
        "\n",
        "path_text = kagglehub.dataset_download(\"rmisra/news-category-dataset\")\n",
        "csv_path = os.path.join(path_text, \"News_Category_Dataset_v3.json\")\n",
        "\n",
        "# dataset is in JSON format with keys: headline, short_description, category, etc.\n",
        "df = pd.read_json(csv_path, lines=True)\n",
        "print(\"Columns:\", list(df.columns))\n",
        "print(\"Total rows:\", len(df))\n",
        "\n",
        "categories_to_keep = ['POLITICS', 'WELLNESS', 'ENTERTAINMENT', 'TRAVEL', 'STYLE & BEAUTY']\n",
        "df = df[df['category'].isin(categories_to_keep)]\n",
        "df = df[['headline', 'short_description', 'category']].dropna()\n",
        "df['text'] = (df['headline'] + \" \" + df['short_description']).astype(str)\n",
        "# We'll combine headline + short_description as text\n",
        "df[\"text\"] = (df[\"headline\"] + \" \" + df[\"short_description\"]).astype(str)\n",
        "df = df[[\"text\", \"category\"]].dropna()\n",
        "\n",
        "# Limit to manageable size for CPU\n",
        "df = df.sample(10000, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df[\"y\"] = le.fit_transform(df[\"category\"])\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", num_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbVFMVEoAJQO",
        "outputId": "611aa4ba-9279-4056-e876-8e8961de84fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n",
            "Using Colab cache for faster access to the 'news-category-dataset' dataset.\n",
            "Columns: ['link', 'headline', 'category', 'short_description', 'authors', 'date']\n",
            "Total rows: 209527\n",
            "Classes: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Text preprocessing\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens\n",
        "\n",
        "df[\"tokens\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "# Build vocabulary\n",
        "from collections import Counter\n",
        "all_tokens = [tok for tokens in df[\"tokens\"] for tok in tokens]\n",
        "vocab_counter = Counter(all_tokens)\n",
        "vocab = [w for w, c in vocab_counter.items() if c >= 3]\n",
        "word2idx = {w: i+2 for i, w in enumerate(vocab)}\n",
        "word2idx[\"<PAD>\"] = 0\n",
        "word2idx[\"<UNK>\"] = 1\n",
        "idx2word = {i:w for w,i in word2idx.items()}\n",
        "\n",
        "vocab_size = len(word2idx)\n",
        "print(\"Vocab size:\", vocab_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcn_gHUxATqG",
        "outputId": "9f23fc12-689d-41a8-ea4b-7f84ccaa70a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 9592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Encode texts as sequences\n",
        "\n",
        "def encode_tokens(tokens, max_len=30):\n",
        "    ids = [word2idx.get(t, 1) for t in tokens]\n",
        "    if len(ids) < max_len:\n",
        "        ids += [0] * (max_len - len(ids))\n",
        "    else:\n",
        "        ids = ids[:max_len]\n",
        "    return ids\n",
        "\n",
        "df[\"ids\"] = df[\"tokens\"].apply(lambda x: encode_tokens(x))\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df[\"ids\"].tolist(), df[\"y\"].values, test_size=0.2, random_state=SEED, stratify=df[\"y\"]\n",
        ")\n",
        "\n",
        "# Dataset & Dataloader\n",
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.long)\n",
        "    def __len__(self): return len(self.y)\n",
        "    def __getitem__(self, i): return self.X[i], self.y[i]\n",
        "\n",
        "train_ds = NewsDataset(X_train, y_train)\n",
        "test_ds  = NewsDataset(X_test,  y_test)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=128)\n"
      ],
      "metadata": {
        "id": "dw3_oSxaAZxR"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Model definitions\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes, pretrained_weights=None):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        if pretrained_weights is not None:\n",
        "            self.embedding.weight.data.copy_(torch.from_numpy(pretrained_weights))\n",
        "            self.embedding.weight.requires_grad = True  # fine-tune\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim*2, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, (h, _) = self.lstm(x)\n",
        "        out = torch.cat((h[0], h[1]), dim=1)\n",
        "        return self.fc(out)"
      ],
      "metadata": {
        "id": "-Y1Qd2cYAcaA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, test_loader, epochs=5, lr=1e-3):\n",
        "    model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_acc = 0\n",
        "    for ep in range(1, epochs+1):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(xb), yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        # Evaluate\n",
        "        acc = evaluate(model, test_loader)\n",
        "        print(f\"[{ep:02d}] loss={total_loss/len(train_loader):.4f} | acc={acc:.4f}\")\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "    return best_acc\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval(); correct=total=0\n",
        "    with torch.no_grad():\n",
        "        for xb,yb in loader:\n",
        "            xb,yb=xb.to(device),yb.to(device)\n",
        "            preds=model(xb).argmax(1)\n",
        "            correct+=(preds==yb).sum().item(); total+=yb.size(0)\n",
        "    return correct/total\n"
      ],
      "metadata": {
        "id": "98KDfnI7AfLL"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Embedding\n",
        "\n",
        "print(\"Random Embedding + LSTM \")\n",
        "embed_dim = 100\n",
        "hidden_dim = 128\n",
        "model_a = LSTMClassifier(vocab_size, embed_dim, hidden_dim, num_classes)\n",
        "acc_a = train_model(model_a, train_loader, test_loader, epochs=5, lr=1e-3)\n",
        "print(f\"(a) Accuracy: {acc_a:.4f}\")\n",
        "\n",
        "\n",
        "#  Pretrained GloVe Embeddings\n",
        "\n",
        "print(\"\\nDownloading GloVe (may take a minute)...\")\n",
        "\n",
        "!pip install -q gensim\n",
        "\n",
        "glove = api.load(\"glove-wiki-gigaword-100\")  # 100-dim\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, idx in word2idx.items():\n",
        "    if word in glove:\n",
        "        embedding_matrix[idx] = glove[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(100,))\n",
        "\n",
        "print(\"GloVe Embedding + LSTM \")\n",
        "model_b = LSTMClassifier(vocab_size, 100, hidden_dim, num_classes,\n",
        "                         pretrained_weights=embedding_matrix)\n",
        "acc_b = train_model(model_b, train_loader, test_loader, epochs=5, lr=1e-3)\n",
        "print(f\"(b) Accuracy: {acc_b:.4f}\")\n",
        "\n",
        "\n",
        "print(\"SUMMARY\")\n",
        "print(f\"Random embedding LSTM accuracy : {acc_a:.4f}\")\n",
        "print(f\"GloVe embedding LSTM accuracy  : {acc_b:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWcflDSLytJV",
        "outputId": "945f6953-c7ce-4e31-f41c-bc32f6f62026"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Embedding + LSTM \n",
            "[01] loss=1.2238 | acc=0.5995\n",
            "[02] loss=0.8456 | acc=0.7000\n",
            "[03] loss=0.5807 | acc=0.7525\n",
            "[04] loss=0.3892 | acc=0.7650\n",
            "[05] loss=0.2433 | acc=0.7830\n",
            "(a) Accuracy: 0.7830\n",
            "\n",
            "Downloading GloVe (may take a minute)...\n",
            "GloVe Embedding + LSTM \n",
            "[01] loss=0.8652 | acc=0.8280\n",
            "[02] loss=0.4294 | acc=0.8560\n",
            "[03] loss=0.2998 | acc=0.8770\n",
            "[04] loss=0.2203 | acc=0.8780\n",
            "[05] loss=0.1563 | acc=0.8765\n",
            "(b) Accuracy: 0.8780\n",
            "SUMMARY\n",
            "Random embedding LSTM accuracy : 0.7830\n",
            "GloVe embedding LSTM accuracy  : 0.8780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У першому експерименті LSTM-модель навчалась із випадково ініціалізованими векторами слів у шарі Embedding. Модель продемонструвала поступове покращення точності протягом епох, проте її фінальний результат залишився обмеженим (0.78), оскільки всі словникові представлення вона мусила вивчати з нуля, використовуючи лише наявний навчальний корпус.\n",
        "\n",
        "У другому експерименті застосовано заздалегідь натреновані вектори GloVe, що вже містять семантичну інформацію про слова, накопичену з великого зовнішнього корпусу. Завдяки цьому модель отримала значно якіснішу початкову репрезентацію тексту, швидше навчилася та досягла вищої точності (0.88). Порівняння двох підходів показує, що використання попередньо навчених ембеддингів суттєво покращує здатність моделі розпізнавати тематичну структуру текстів та забезпечує кращу загальну продуктивність порівняно з випадковою ініціалізацією."
      ],
      "metadata": {
        "id": "iNeibUkQ7YTs"
      }
    }
  ]
}