{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NataliaGon/kpi/blob/AI-cybersecurity/Lab7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruTzXCt1Ht-a"
      },
      "source": [
        "# Метод до чутливого розташування хешування в системах машинного навчання"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "q2udpQpmDDQf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import kagglehub\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from numpy.linalg import norm\n",
        "from collections import Counter\n",
        "from collections import defaultdict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r-KZHJ3ICjD",
        "outputId": "bfb7f51d-2c86-4073-8e8e-6802ec3bbcfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/phucthaiv02/butterfly-image-classification/versions/3\n",
            "Files in dataset folder: ['Testing_set.csv', 'test', 'train', 'Training_set.csv']\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
        "\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "print(\"Files in dataset folder:\", os.listdir(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQLpphuTJPw5",
        "outputId": "b4a856e1-623c-4678-ef3a-ab0f29ce614d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train samples in CSV: 6499\n"
          ]
        }
      ],
      "source": [
        "base_path = \"/root/.cache/kagglehub/datasets/phucthaiv02/butterfly-image-classification/versions/3\"\n",
        "\n",
        "train_csv = pd.read_csv(os.path.join(base_path, \"Training_set.csv\"))\n",
        "train_dir = os.path.join(base_path, \"train\")\n",
        "\n",
        "print(\"Train samples in CSV:\", len(train_csv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZKqWA0jWgd1",
        "outputId": "b9985e9a-96ba-48db-e43d-b4c85d23d325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN columns: ['filename', 'label']\n",
            "      filename                     label\n",
            "0  Image_1.jpg          SOUTHERN DOGFACE\n",
            "1  Image_2.jpg                    ADONIS\n",
            "2  Image_3.jpg            BROWN SIPROETA\n",
            "3  Image_4.jpg                   MONARCH\n",
            "4  Image_5.jpg  GREEN CELLED CATTLEHEART\n"
          ]
        }
      ],
      "source": [
        "print(\"TRAIN columns:\", train_csv.columns.tolist())\n",
        "print(train_csv.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAro0ZgXP22s",
        "outputId": "2a511233-5897-42c9-fa59-e2db65093f50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 6499/6499 [00:12<00:00, 529.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All train shape: (6499, 12288) classes: 75\n",
            "Train: (5199, 12288) Val: (1300, 12288)\n"
          ]
        }
      ],
      "source": [
        "X = []\n",
        "y = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "def load_images_labeled(base_dir, csv_file):\n",
        "    X, y = [], []\n",
        "    for _, row in tqdm(csv_file.iterrows(), total=len(csv_file)):\n",
        "        img_path = os.path.join(base_dir, row[\"filename\"])\n",
        "        if not os.path.isfile(img_path):\n",
        "            continue\n",
        "        img = Image.open(img_path).convert(\"RGB\").resize((64, 64))\n",
        "        arr = np.array(img, dtype=\"float32\") / 255.0\n",
        "        X.append(arr.flatten())\n",
        "        y.append(row[\"label\"])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "X, y = load_images_labeled(train_dir, train_csv)\n",
        "print(\"All train shape:\", X.shape, \"classes:\", len(np.unique(y)))\n",
        "\n",
        "X_train, X_test, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Train:\", X_train.shape, \"Val:\", X_test.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUFEDwcGL4FP"
      },
      "source": [
        "**Locality Sensitive Hashing (LSH)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "VsvOCHlYMCA1"
      },
      "outputs": [],
      "source": [
        "class LSH:\n",
        "    def __init__(self, num_buckets=1000, num_hash_functions=10, input_dim=128, seed=42):\n",
        "        self.num_buckets = num_buckets\n",
        "        self.num_hash_functions = num_hash_functions\n",
        "        self.input_dim = input_dim\n",
        "        rng = np.random.default_rng(seed)\n",
        "        # кожна хеш-функція — це гіперплощина\n",
        "        self.hash_functions = [rng.standard_normal(input_dim) for _ in range(num_hash_functions)]\n",
        "        # робимо словник замість фіксованого масиву\n",
        "        self.buckets = defaultdict(list)\n",
        "\n",
        "    def _hash_vector(self, vector):\n",
        "        # отримаємо бітовий підпис, напр. [1,0,1,1,0,...]\n",
        "        bits = []\n",
        "        for h in self.hash_functions:\n",
        "            proj = np.dot(vector, h)\n",
        "            bits.append(1 if proj > 0 else 0)\n",
        "        # перетворимо біти в одне число\n",
        "        hval = 0\n",
        "        for b in bits:\n",
        "            hval = (hval << 1) | b\n",
        "        return hval % self.num_buckets\n",
        "\n",
        "    def add_vector(self, idx, vector):\n",
        "        h = self._hash_vector(vector)\n",
        "        self.buckets[h].append(idx)\n",
        "\n",
        "    def query(self, query_vector):\n",
        "        h = self._hash_vector(query_vector)\n",
        "        # повертаємо кандидатів (індекси)\n",
        "        return self.buckets.get(h, [])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SC9Y0peoPjgG",
        "outputId": "a1258fd0-d7bf-413f-9f14-9767a345d69a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSH accuracy (validation, on found): 0.029526029526029528\n",
            "                           precision    recall  f1-score   support\n",
            "\n",
            "                   ADONIS       0.01      0.06      0.01        18\n",
            "AFRICAN GIANT SWALLOWTAIL       0.03      0.33      0.05        15\n",
            "           AMERICAN SNOOT       0.00      0.00      0.00        14\n",
            "                    AN 88       0.00      0.00      0.00        17\n",
            "                  APPOLLO       0.00      0.00      0.00        18\n",
            "                    ATALA       0.14      0.05      0.07        20\n",
            " BANDED ORANGE HELICONIAN       0.00      0.00      0.00        20\n",
            "           BANDED PEACOCK       0.00      0.00      0.00        17\n",
            "            BECKERS WHITE       0.00      0.00      0.00        15\n",
            "         BLACK HAIRSTREAK       0.00      0.00      0.00        17\n",
            "              BLUE MORPHO       0.00      0.00      0.00        15\n",
            "        BLUE SPOTTED CROW       0.00      0.00      0.00        17\n",
            "           BROWN SIPROETA       0.00      0.00      0.00        20\n",
            "            CABBAGE WHITE       0.00      0.00      0.00        18\n",
            "          CAIRNS BIRDWING       0.00      0.00      0.00        16\n",
            "       CHECQUERED SKIPPER       0.00      0.00      0.00        19\n",
            "                 CHESTNUT       0.00      0.00      0.00        17\n",
            "                CLEOPATRA       0.00      0.00      0.00        19\n",
            "       CLODIUS PARNASSIAN       0.04      0.24      0.07        17\n",
            "          CLOUDED SULPHUR       0.08      0.06      0.07        18\n",
            "        COMMON BANDED AWL       0.00      0.00      0.00        17\n",
            "        COMMON WOOD-NYMPH       0.00      0.00      0.00        18\n",
            "              COPPER TAIL       0.00      0.00      0.00        19\n",
            "                  CRECENT       0.00      0.00      0.00        20\n",
            "            CRIMSON PATCH       0.00      0.00      0.00        14\n",
            "            DANAID EGGFLY       0.00      0.00      0.00        19\n",
            "             EASTERN COMA       0.03      0.11      0.04        19\n",
            "     EASTERN DAPPLE WHITE       0.00      0.00      0.00        18\n",
            "       EASTERN PINE ELFIN       0.00      0.00      0.00        19\n",
            "          ELBOWED PIERROT       0.00      0.00      0.00        16\n",
            "              GOLD BANDED       0.00      0.00      0.00        15\n",
            "             GREAT EGGFLY       0.00      0.00      0.00        16\n",
            "                GREAT JAY       0.03      0.05      0.04        19\n",
            " GREEN CELLED CATTLEHEART       0.00      0.00      0.00        17\n",
            "          GREY HAIRSTREAK       0.05      0.24      0.08        17\n",
            "            INDRA SWALLOW       0.00      0.00      0.00        15\n",
            "          IPHICLUS SISTER       0.00      0.00      0.00        19\n",
            "                    JULIA       0.00      0.00      0.00        16\n",
            "             LARGE MARBLE       0.03      0.06      0.04        16\n",
            "                MALACHITE       0.00      0.00      0.00        15\n",
            "         MANGROVE SKIPPER       0.00      0.00      0.00        17\n",
            "                   MESTRA       0.00      0.00      0.00        17\n",
            "                METALMARK       0.00      0.00      0.00        15\n",
            "   MILBERTS TORTOISESHELL       0.00      0.00      0.00        19\n",
            "                  MONARCH       0.00      0.00      0.00        18\n",
            "           MOURNING CLOAK       0.11      0.15      0.13        26\n",
            "           ORANGE OAKLEAF       0.00      0.00      0.00        16\n",
            "               ORANGE TIP       0.07      0.26      0.12        19\n",
            "          ORCHARD SWALLOW       0.00      0.00      0.00        14\n",
            "             PAINTED LADY       0.00      0.00      0.00        16\n",
            "               PAPER KITE       0.00      0.00      0.00        18\n",
            "                  PEACOCK       0.00      0.00      0.00        17\n",
            "               PINE WHITE       0.00      0.00      0.00        17\n",
            "         PIPEVINE SWALLOW       0.00      0.00      0.00        17\n",
            "                 POPINJAY       0.00      0.00      0.00        17\n",
            "        PURPLE HAIRSTREAK       0.00      0.00      0.00        16\n",
            "          PURPLISH COPPER       0.00      0.00      0.00        18\n",
            "            QUESTION MARK       0.00      0.00      0.00        15\n",
            "              RED ADMIRAL       0.00      0.00      0.00        16\n",
            "              RED CRACKER       0.00      0.00      0.00        19\n",
            "              RED POSTMAN       0.05      0.19      0.08        16\n",
            "       RED SPOTTED PURPLE       0.00      0.00      0.00        16\n",
            "           SCARCE SWALLOW       0.02      0.05      0.02        20\n",
            "      SILVER SPOT SKIPPER       0.00      0.00      0.00        16\n",
            "            SLEEPY ORANGE       0.00      0.00      0.00        22\n",
            "                SOOTYWING       0.04      0.24      0.06        17\n",
            "         SOUTHERN DOGFACE       0.00      0.00      0.00        17\n",
            "           STRAITED QUEEN       0.00      0.00      0.00        16\n",
            "        TROPICAL LEAFWING       0.00      0.00      0.00        17\n",
            "       TWO BARRED FLASHER       0.00      0.00      0.00        15\n",
            "                   ULYSES       0.00      0.00      0.00        17\n",
            "                  VICEROY       0.11      0.06      0.08        16\n",
            "               WOOD SATYR       0.00      0.00      0.00        14\n",
            "      YELLOW SWALLOW TAIL       0.00      0.00      0.00        15\n",
            "          ZEBRA LONG WING       0.00      0.00      0.00        15\n",
            "\n",
            "                 accuracy                           0.03      1287\n",
            "                macro avg       0.01      0.03      0.01      1287\n",
            "             weighted avg       0.01      0.03      0.01      1287\n",
            "\n",
            "Used 1287 val images out of 1300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# 7. build LSH on OUR train part\n",
        "lsh = LSH(num_buckets=2048,\n",
        "          num_hash_functions=12,\n",
        "          input_dim=X_train.shape[1])\n",
        "\n",
        "for i, v in enumerate(X_train):\n",
        "    lsh.add_vector(i, v)\n",
        "\n",
        "# 8. evaluate LSH on validation part\n",
        "def cosine_sim(a, b):\n",
        "    return np.dot(a, b) / (norm(a) * norm(b) + 1e-8)\n",
        "\n",
        "y_pred_lsh = []\n",
        "y_true_lsh = []\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "    q = X_test[i]\n",
        "    true_label = y_val[i]\n",
        "\n",
        "    cand_idx = lsh.query(q)\n",
        "    if not cand_idx:\n",
        "        continue  # no candidates in that bucket\n",
        "\n",
        "    # majority in bucket (simple)\n",
        "    cand_labels = [y_train[j] for j in cand_idx]\n",
        "    most_common_label, _ = Counter(cand_labels).most_common(1)[0]\n",
        "\n",
        "    y_true_lsh.append(true_label)\n",
        "    y_pred_lsh.append(most_common_label)\n",
        "\n",
        "print(\"LSH accuracy (validation, on found):\",\n",
        "      accuracy_score(y_true_lsh, y_pred_lsh))\n",
        "print(classification_report(y_true_lsh, y_pred_lsh))\n",
        "print(\"Used\", len(y_true_lsh), \"val images out of\", len(X_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Logistic regression**"
      ],
      "metadata": {
        "id": "p-BQsaTOzWvY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YbIi07zKpuRC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7aae78e-d4cf-4edf-f3da-bb8eb0045f4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression accuracy: 0.3230769230769231\n"
          ]
        }
      ],
      "source": [
        "clf = LogisticRegression(max_iter=500)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred_val = clf.predict(X_test)\n",
        "\n",
        "print(\"Logistic Regression accuracy:\", accuracy_score(y_val, y_pred_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Висновки**"
      ],
      "metadata": {
        "id": "0DLXc0DCzcAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У цій роботі я взяла датасет з Kaggle (Butterfly Image Classification) і перетворила зображення у числові вектори фіксованого розміру 64×64×3 = 12 288 ознак. На основі цих ознак ти побудувала власний train–test split (80/20), бо в наданому Kaggle-тесті не було міток, тобто його не можна було використати для оцінювання. Це правильне рішення, бо інакше порівняння LSH із класичною класифікацією було б неможливим.\n",
        "\n",
        "Метод LSH реалізовано на основі випадкових гіперплощин, які формують бітові підписи векторів зображень і розподіляють їх по «бакетах» за схожістю. Для кожного зображення тестової вибірки здійснювався пошук схожих елементів у відповідному бакеті, а прогнозована мітка визначалася за принципом більшості серед знайдених сусідів. Як базовий підхід для порівняння використано метод логістичної регресії, натренований на тих самих даних.\n",
        "\n",
        "Отримані результати показали, що LSH продемонстрував значно нижчу точність класифікації порівняно з логістичною регресією. Це пояснюється тим, що LSH є наближеним методом, оптимізованим для швидкого пошуку подібних об’єктів у високовимірних просторах, а не для точного багатокласового навчання на сирих піксельних даних. Попри це, експеримент підтвердив здатність LSH ефективно скорочувати простір пошуку та може бути корисним як попередній етап для відбору кандидатів у системах обробки великих обсягів зображень. Таким чином, робота продемонструвала практичне застосування LSH у системах машинного навчання та його відмінності від традиційних методів класифікації за точністю та обчислювальною складністю."
      ],
      "metadata": {
        "id": "CHfUbfpa2xE4"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLRuzxAZVab2Vzenuxt37p",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}